/*!
 * \file basicMath.h
 * \author Basilio Noris
 * \date 27-11-06
 */
#ifndef _BASICMATH_H_
#define _BASICMATH_H_

#include <vector>
#include "basicOpenCV.h"

#define PIf	3.1415926535897932384626433832795f
//#define cvVec2 CvPoint2D32f
#define Vec3 CvPoint3D32f
#define cvvec2(a,b) cvPoint2D32f(a,b)
#define vec3(a,b,c) cvPoint3D32f(a,b,c)
#define point2(a) cvPoint((int)a.x, (int)a.y)

class cvVec2: public CvPoint2D32f{
public:
	float x, y;
	// constructors
	cvVec2() : x(0), y(0) {}
	cvVec2(int a, int b): x((float)a), y((float)b) {}
	cvVec2(float a, float b): x(a), y(b) {}
	cvVec2(double a, double b): x((float)a), y((float)b) {}
	cvVec2(CvPoint a): x((float)a.x), y((float)a.y) {}
	cvVec2(CvPoint2D32f a): x(a.x), y(a.y) {}
	CvPoint2D32f to32f(){return cvPoint2D32f(x,y);}
	CvPoint to2d(){return cvPoint((int)x,(int)y);}

	//operators
	cvVec2 operator+(const cvVec2&v) const {
		return cvVec2(x + v.x, y + v.y);
	}

	cvVec2& operator+=(const cvVec2&v) {
		x += v.x;
		y += v.y;
		return *this;
	}

	cvVec2 operator-(const cvVec2&v) const {
		return cvVec2(x - v.x, y - v.y);
	}

	cvVec2& operator-=(const cvVec2&v) {
		x -= v.x;
		y -= v.y;
		return *this;
	}

	cvVec2 operator*(const float &d) const {
		return cvVec2(x * d, y * d);
	}

	cvVec2& operator*=(const float &d) {
		x *= d;
		y *= d;
		return *this;
	}

	cvVec2 operator/(const float &d) const {
		return cvVec2(x / d, y / d);
	}

	cvVec2& operator/=(const float &d) {
		assert(d!=0);
		float inv = 1.f / d;
		x *= inv;
		y *= inv;
		return *this;
	}

	bool operator==(const cvVec2&v) const {
		return x == v.x && y == v.y;
	}

	bool operator!=(const cvVec2&v) const {
		return x != v.x || y != v.y;
	}

	cvVec2 operator-() const {
		return cvVec2(-x, -y);
	}

	// other functions
	cvVec2 normalize() { 
		if(length() <= 0) return cvVec2(1,0);
		float l = length();
		x /= l;
		y /= l;
		return *this;
	}

	float lengthSquared() {
		return x * x + y * y;
	}

	float length() {
		return sqrt(lengthSquared());
	}

	float dot(const cvVec2&v) const {
		return x * v.x + y * v.y;
	}
};

static float Distance(CvPoint2D32f a, CvPoint2D32f b)
{
	return (float)sqrt((b.x - a.x)*(b.x - a.x) + (b.y - a.y)*(b.y - a.y));
}

static float Distance(Vec3 a, Vec3 b)
{
	return (float)sqrt((b.x - a.x)*(b.x - a.x) + (b.y - a.y)*(b.y - a.y) + (b.z - a.z)*(b.z - a.z));
}

static u32 *FindMatches(CvPoint2D32f *src, u32 srccnt, CvPoint2D32f *dst, u32 dstcnt){
	f32 *distances = new f32[dstcnt*srccnt];
	FOR(i, dstcnt){
		f32 distotal = 0;
		FOR(j, srccnt){
			distances[i*srccnt + j] = Distance(src[j],dst[i]);
			distotal += distances[i*srccnt + j];
		}
		FOR(j,srccnt){
			distances[i*srccnt + j] /= distotal;
		}
	}
	u32 *indices = new u32[dstcnt];
	FOR(j,dstcnt){
		u32 minind = 0;
		FOR(i,dstcnt*srccnt){
			if(distances[i] < distances[minind]) minind = i;
		}
		indices[minind/srccnt] = minind%srccnt;
		FOR(i,srccnt){
			distances[(minind/srccnt)*srccnt + i] = 1.0f;
		}
		FOR(i,dstcnt){
			distances[i*srccnt + minind%srccnt] = 1.0f;
		}
	}
	delete [] distances;
	return indices;
}

static float Angle(Vec3 a, Vec3 b)
{
	// acos( a.b / |a|.|b|)
	float phi = (a.x*b.x+a.y*b.y+a.z+b.z) / sqrtf((a.x*a.x+a.y*a.y+a.z*a.z)*(b.x*b.x+b.y*b.y+b.z*b.z));
	return acos(phi);
}

/*!
 * Cubic interpolation class adapted from an algorithm by Marino 'Mutilate' Alge
 * works with cvVec2 and Vec3 types
 */
template <class T>
class CCubic
{
private:
	T a, b, c, d;

public:
	/*!
		Constructor, takes 4 points as input for the interpolation
		\param x0-x3 the input points for interpolation
	*/
	CCubic(T x0, T x1, T x2, T x3)
	{
//		a = x1;
//		b = (x2 - x0)*0.5f;
//		c = x0 - x1*2.5f + x2*2.0f - x3*0.5f;
//		d = (x3 - x0)*0.5f - (x2 - x1)*1.5f;
		a = x1;
		b = MulS(Sub(x2,x0),0.5f);
		c = Add(Sub(x0,MulS(x1,2.5f)),Sub(MulS(x2,2.0f),MulS(x3,0.5f)));
		d = Sub(MulS(Sub(x3,x0),0.5f),MulS(Sub(x2,x1),1.5f));
	}

	/*!
		The interpolation prediction function
		\param t the input time
		\return returns the value expected at time t
	*/
	T X(float t) const
	{
		//return a + (b + (c + d*t)*t)*t;
		return Add(a,MulS(Add(b,MulS(Add(c,MulS(d,t)),t)),t));
	}

	/*!
		All in one interpolation function
		\param x0-x3 the input points for interpolation
		\param t the input time
		\return returns the value expected at time t, using points x0-x3 for interpolation
	*/
	static T X(T x0, T x1, T x2, T x3, float t)
	{
		//return x1 + ((x2 - x0)*0.5f + (x0 - x1*2.5f + x2*2.0f - x3*0.5f + (x3 - x0)*0.5f - (x2 - x1)*1.5f*t)*t)*t;
		T asd7 = Sub(x0, MulS(x1,2.5f));
		T asd6 = Sub(MulS(x2,2.0f), MulS(x3,0.5f));
		T asd5 = Sub(MulS(Sub(x3,x0),0.5f), MulS(Sub(x2,x1),1.5f*t));
		T asd4 = Add(asd5,Add(asd6,asd7));
		T asd3 = MulS(asd4,t);
		T asd2 = Add(MulS(Sub(x2,x0),0.5f), asd3);
		T asd  = MulS(asd2,t);
		return Add(x1, asd);
	}
};

/*!
	Random Permutations array
	\param length the length of the output array
	\param seed random seed (optional) clock used otherwise
	\return returns an array of indices between 0 and 'length' randomly sorted
*/
static u32 *randPerm(u32 length, s32 seed=-1)
{
	u32 *perm = new u32[length];
	memset(perm, 0, length*sizeof(u32));

	u32 *usable = new u32[length];
	FOR(i, length) usable[i] = i;

	if(seed == -1) srand((u32)cvGetTickCount());
	else srand((u32)seed);

	u32 uLength = length;
    for (u32 i=0; i<length; i++)
	{
        u32 r = ((rand()<< 7) + rand()) % uLength;

		perm[i] = usable[r];
		uLength--;
		usable[r] = usable[uLength];
		usable[uLength] = 0;
	}
	delete [] usable;
	
	return perm;
}


// matlab code to generate the table
// erf(x) = (x>0?1:-1) * erftable((int)(min(6,abs(x))*100));
// 0:0.01:6
static const float erftable [] = 
{
	0.0000000000000000f, 0.0112834155558496f, 0.0225645746918449f, 0.0338412223417354f, 0.0451111061451247f, 0.0563719777970166f, 0.0676215943933084f, 0.0788577197708907f, 0.0900781258410182f, 0.1012805939146269f, 0.1124629160182849f, 0.1236228961994743f, 0.1347583518199201f, 0.1458671148356958f, 0.1569470330628558f, 0.1679959714273635f, 0.1790118131981057f, 0.1899924612018088f, 0.2009358390186958f, 0.2118398921577497f, 0.2227025892104785f, 0.2335219229821036f, 0.2442959115991287f, 0.2550225995922731f, 0.2657000589537920f, 0.2763263901682369f, 0.2868997232157491f, 0.2974182185470128f, 0.3078800680290340f, 0.3182834958609522f, 0.3286267594591273f, 0.3389081503107902f, 0.3491259947955827f, 0.3592786549743590f, 0.3693645293446587f, 0.3793820535623103f, 0.3893297011286642f, 0.3992059840429992f, 0.4090094534196940f, 0.4187387000697961f, 0.4283923550466685f, 0.4379690901554394f, 0.4474676184260253f, 0.4568866945495403f, 0.4662251152779575f, 0.4754817197869237f, 0.4846553900016797f, 0.4937450508860821f, 0.5027496706947650f, 0.5116682611885233f, 0.5204998778130465f, 0.5292436198411704f, 0.5378986304788544f, 0.5464640969351416f, 0.5549392504563904f, 0.5633233663251089f, 0.5716157638237684f, 0.5798158061639961f, 0.5879229003816007f, 0.5959364971979084f, 0.6038560908479259f, 0.6116812188758802f, 0.6194114618987212f, 0.6270464433381957f, 0.6345858291221413f, 0.6420293273556719f, 0.6493766879629542f, 0.6566277023003051f, 0.6637822027413580f, 0.6708400622350779f, 0.6778011938374186f, 0.6846655502174442f, 0.6914331231387512f, 0.6981039429170445f, 0.7046780778547458f, 0.7111556336535152f, 0.7175367528055909f, 0.7238216139648592f, 0.7300104312985789f, 0.7361034538206912f, 0.7421009647076605f, 0.7480032805977895f, 0.7538107508749625f, 0.7595237569377731f, 0.7651427114549946f, 0.7706680576083524f, 0.7761002683235567f, 0.7814398454905507f, 0.7866873191739325f, 0.7918432468144954f, 0.7969082124228322f, 0.8018828257659413f, 0.8067677215477618f, 0.8115635585845578f, 0.8162710189760625f, 0.8208908072732779f, 0.8254236496438183f, 0.8298702930356671f, 0.8342315043402079f, 0.8385080695553697f, 0.8427007929497148f, 0.8468104962282766f, 0.8508380177009420f, 0.8547842114541484f, 0.8586499465266515f, 0.8624361060900967f, 0.8661435866351080f, 0.8697732971635868f, 0.8733261583878896f, 0.8768031019375383f, 0.8802050695740817f, 0.8835330124147180f, 0.8867878901652547f, 0.8899706703629624f, 0.8930823276298567f, 0.8961238429369151f, 0.8990962028797120f, 0.9020003989659357f, 0.9048374269152169f, 0.9076082859716850f, 0.9103139782296355f, 0.9129555079726694f, 0.9155338810266469f, 0.9180501041267614f, 0.9205051842990297f, 0.9229001282564582f, 0.9252359418101295f, 0.9275136292954247f, 0.9297341930135782f, 0.9318986326887336f, 0.9340079449406524f, 0.9360631227731995f, 0.9380651550787114f, 0.9400150261583302f, 0.9419137152583653f, 0.9437621961227241f, 0.9455614365614331f, 0.9473123980352520f, 0.9490160352563626f, 0.9506732958050965f, 0.9522851197626489f, 0.9538524393597054f, 0.9553761786408961f, 0.9568572531449688f, 0.9582965696005648f, 0.9596950256374592f, 0.9610535095131181f, 0.9623728998544057f, 0.9636540654142689f, 0.9648978648432043f, 0.9661051464753108f, 0.9672767481287117f, 0.9684134969201232f, 0.9695162090933357f, 0.9705856898613637f, 0.9716227332620125f, 0.9726281220266002f, 0.9736026274615670f, 0.9745470093426969f, 0.9754620158216676f, 0.9763483833446440f, 0.9772068365826185f, 0.9780380883732035f, 0.9788428396735702f, 0.9796217795242320f, 0.9803755850233603f, 0.9811049213113221f, 0.9818104415651265f, 0.9824927870024649f, 0.9831525868950262f, 0.9837904585907746f, 0.9844070075448683f, 0.9850028273589058f, 0.9855784998281805f, 0.9861345949966329f, 0.9866716712191824f, 0.9871902752311301f, 0.9876909422243223f, 0.9881741959297683f, 0.9886405487064082f, 0.9890905016357308f, 0.9895245446219444f, 0.9899431564974077f, 0.9903468051330306f, 0.9907359475533626f, 0.9911110300560857f, 0.9914724883356396f, 0.9918207476107068f, 0.9921562227552937f, 0.9924793184331480f, 0.9927904292352574f, 0.9930899398201836f, 0.9933782250569847f, 0.9936556501704964f, 0.9939225708887325f, 0.9941793335921891f, 0.9944262754648279f, 0.9946637246465300f, 0.9948920003868136f, 0.9951114131996171f, 0.9953222650189527f, 0.9955248493552482f, 0.9957194514521921f, 0.9959063484439121f, 0.9960858095123195f, 0.9962580960444569f, 0.9964234617896959f, 0.9965821530166383f, 0.9967344086695764f, 0.9968804605243777f, 0.9970205333436670f, 0.9971548450311778f, 0.9972836067851606f, 0.9974070232507333f, 0.9975252926710697f, 0.9976386070373253f, 0.9977471522372077f, 0.9978511082021002f, 0.9979506490526588f, 0.9980459432428015f, 0.9981371537020181f, 0.9982244379759344f, 0.9983079483650648f, 0.9983878320616981f, 0.9984642312848625f, 0.9985372834133188f, 0.9986071211165417f, 0.9986738724836455f, 0.9987376611502190f, 0.9987986064230412f, 0.9988568234026434f, 0.9989124231037001f, 0.9989655125732240f, 0.9990161950065498f, 0.9990645698610920f, 0.9991107329678676f, 0.9991547766407751f, 0.9991967897836264f, 0.9992368579949287f, 0.9992750636704192f, 0.9993114861033550f, 0.9993462015825647f, 0.9993792834882711f, 0.9994108023856942f, 0.9994408261164486f, 0.9994694198877490f, 0.9994966463594419f, 0.9995225657288811f, 0.9995472358136659f, 0.9995707121322661f, 0.9995930479825550f, 0.9996142945182758f, 0.9996345008234653f, 0.9996537139848649f, 0.9996719791623431f, 0.9996893396573607f, 0.9997058369795080f, 0.9997215109111428f, 0.9997363995701628f, 0.9997505394709432f, 0.9997639655834707f, 0.9997767113907082f, 0.9997888089442237f, 0.9998002889181156f, 0.9998111806612684f, 0.9998215122479760f, 0.9998313105269614f, 0.9998406011688324f, 0.9998494087120056f, 0.9998577566071316f, 0.9998656672600594f, 0.9998731620733716f, 0.9998802614865254f, 0.9998869850146334f, 0.9998933512859194f, 0.9998993780778804f, 0.9999050823521898f, 0.9999104802883753f, 0.9999155873163016f, 0.9999204181474947f, 0.9999249868053346f, 0.9999293066541523f, 0.9999333904272598f, 0.9999372502539452f, 0.9999408976854610f, 0.9999443437200386f, 0.9999475988269556f, 0.9999506729696857f, 0.9999535756281590f, 0.9999563158201617f, 0.9999589021219005f, 0.9999613426877595f, 0.9999636452692755f, 0.9999658172333573f, 0.9999678655797740f, 0.9999697969579359f, 0.9999716176829931f, 0.9999733337512747f, 0.9999749508550908f, 0.9999764743969193f, 0.9999779095030015f, 0.9999792610363629f, 0.9999805336092855f, 0.9999817315952467f, 0.9999828591403461f, 0.9999839201742398f, 0.9999849184206001f, 0.9999858574071167f, 0.9999867404750594f, 0.9999875707884177f, 0.9999883513426329f, 0.9999890849729398f, 0.9999897743623336f, 0.9999904220491747f, 0.9999910304344468f, 0.9999916017886847f, 0.9999921382585810f, 0.9999926418732865f, 0.9999931145504183f, 0.9999935581017863f, 0.9999939742388482f, 0.9999943645779092f, 0.9999947306450711f, 0.9999950738809456f, 0.9999953956451422f, 0.9999956972205364f, 0.9999959798173321f, 0.9999962445769250f, 0.9999964925755764f, 0.9999967248279045f, 0.9999969422902035f, 0.9999971458635975f, 0.9999973363970345f, 0.9999975146901312f, 0.9999976814958739f, 0.9999978375231799f, 0.9999979834393308f, 0.9999981198722784f, 0.9999982474128331f, 0.9999983666167385f, 0.9999984780066371f, 0.9999985820739346f, 0.9999986792805644f, 0.9999987700606605f, 0.9999988548221410f, 0.9999989339482065f, 0.9999990077987595f, 0.9999990767117464f, 0.9999991410044279f, 0.9999992009745795f, 0.9999992569016276f, 0.9999993090477226f, 0.9999993576587528f, 0.9999994029653040f, 0.9999994451835634f, 0.9999994845161754f, 0.9999995211530479f, 0.9999995552721144f, 0.9999995870400529f, 0.9999996166129631f, 0.9999996441370069f, 0.9999996697490110f, 0.9999996935770344f, 0.9999997157409060f, 0.9999997363527273f, 0.9999997555173494f, 0.9999997733328196f, 0.9999997898908039f, 0.9999998052769828f, 0.9999998195714259f, 0.9999998328489421f, 0.9999998451794108f, 0.9999998566280922f, 0.9999998672559198f, 0.9999998771197746f, 0.9999998862727435f, 0.9999998947643614f, 0.9999999026408388f, 0.9999999099452765f, 0.9999999167178646f, 0.9999999229960725f, 0.9999999288148247f, 0.9999999342066670f, 0.9999999392019217f, 0.9999999438288334f, 0.9999999481137065f, 0.9999999520810322f, 0.9999999557536089f, 0.9999999591526549f, 0.9999999622979134f, 0.9999999652077514f, 0.9999999678992515f, 0.9999999703882987f, 0.9999999726896611f, 0.9999999748170654f, 0.9999999767832677f, 0.9999999786001196f, 0.9999999802786297f, 0.9999999818290218f, 0.9999999832607887f, 0.9999999845827421f, 0.9999999858030606f, 0.9999999869293328f, 0.9999999879685986f, 0.9999999889273877f, 0.9999999898117551f, 0.9999999906273142f, 0.9999999913792682f, 0.9999999920724392f, 0.9999999927112944f, 0.9999999932999724f, 0.9999999938423057f, 0.9999999943418427f, 0.9999999948018690f, 0.9999999952254246f, 0.9999999956153229f, 0.9999999959741669f, 0.9999999963043638f, 0.9999999966081397f, 0.9999999968875528f, 0.9999999971445058f, 0.9999999973807567f, 0.9999999975979301f, 0.9999999977975265f, 0.9999999979809319f, 0.9999999981494259f, 0.9999999983041898f, 0.9999999984463144f, 0.9999999985768053f, 0.9999999986965913f, 0.9999999988065282f, 0.9999999989074059f, 0.9999999989999523f, 0.9999999990848385f, 0.9999999991626829f, 0.9999999992340556f, 0.9999999992994814f, 0.9999999993594437f, 0.9999999994143880f, 0.9999999994647240f, 0.9999999995108290f, 0.9999999995530502f, 0.9999999995917070f, 0.9999999996270934f, 0.9999999996594795f, 0.9999999996891137f, 0.9999999997162244f, 0.9999999997410216f, 0.9999999997636982f, 0.9999999997844314f, 0.9999999998033839f, 0.9999999998207052f, 0.9999999998365327f, 0.9999999998509920f, 0.9999999998641989f, 0.9999999998762595f, 0.9999999998872711f, 0.9999999998973228f, 0.9999999999064966f, 0.9999999999148674f, 0.9999999999225040f, 0.9999999999294694f, 0.9999999999358213f, 0.9999999999416126f, 0.9999999999468917f, 0.9999999999517030f, 0.9999999999560869f, 0.9999999999600808f, 0.9999999999637186f, 0.9999999999670313f, 0.9999999999700474f, 0.9999999999727929f, 0.9999999999752915f, 0.9999999999775653f, 0.9999999999796336f, 0.9999999999815150f, 0.9999999999832258f, 0.9999999999847813f, 0.9999999999861953f, 0.9999999999874802f, 0.9999999999886479f, 0.9999999999897087f, 0.9999999999906721f, 0.9999999999915470f, 0.9999999999923415f, 0.9999999999930624f, 0.9999999999937168f, 0.9999999999943107f, 0.9999999999948495f, 0.9999999999953380f, 0.9999999999957810f, 0.9999999999961828f, 0.9999999999965470f, 0.9999999999968769f, 0.9999999999971760f, 0.9999999999974469f, 0.9999999999976923f, 0.9999999999979145f, 0.9999999999981156f, 0.9999999999982978f, 0.9999999999984626f, 0.9999999999986117f, 0.9999999999987466f, 0.9999999999988686f, 0.9999999999989789f, 0.9999999999990787f, 0.9999999999991689f, 0.9999999999992504f, 0.9999999999993240f, 0.9999999999993905f, 0.9999999999994507f, 0.9999999999995048f, 0.9999999999995539f, 0.9999999999995981f, 0.9999999999996381f, 0.9999999999996740f, 0.9999999999997065f, 0.9999999999997358f, 0.9999999999997622f, 0.9999999999997861f, 0.9999999999998075f, 0.9999999999998268f, 0.9999999999998444f, 0.9999999999998600f, 0.9999999999998741f, 0.9999999999998870f, 0.9999999999998983f, 0.9999999999999087f, 0.9999999999999181f, 0.9999999999999263f, 0.9999999999999338f, 0.9999999999999407f, 0.9999999999999467f, 0.9999999999999523f, 0.9999999999999572f, 0.9999999999999616f, 0.9999999999999655f, 0.9999999999999691f, 0.9999999999999722f, 0.9999999999999751f, 0.9999999999999778f, 0.9999999999999800f, 0.9999999999999821f, 0.9999999999999840f, 0.9999999999999857f, 0.9999999999999871f, 0.9999999999999885f, 0.9999999999999898f, 0.9999999999999908f, 0.9999999999999918f, 0.9999999999999927f, 0.9999999999999933f, 0.9999999999999941f, 0.9999999999999947f, 0.9999999999999953f, 0.9999999999999958f, 0.9999999999999962f, 0.9999999999999967f, 0.9999999999999970f, 0.9999999999999973f, 0.9999999999999976f, 0.9999999999999979f, 0.9999999999999981f, 0.9999999999999983f, 0.9999999999999985f, 0.9999999999999987f, 0.9999999999999988f, 0.9999999999999989f, 0.9999999999999991f, 0.9999999999999991f, 0.9999999999999992f, 0.9999999999999993f, 0.9999999999999993f, 0.9999999999999994f, 0.9999999999999996f, 0.9999999999999996f, 0.9999999999999996f, 0.9999999999999997f, 0.9999999999999998f, 0.9999999999999998f, 0.9999999999999998f, 0.9999999999999998f, 0.9999999999999998f, 0.9999999999999998f, 0.9999999999999998f, 0.9999999999999999f, 0.9999999999999999f, 0.9999999999999999f, 0.9999999999999999f, 1.0000000000000000f, 1.0000000000000000f, 1.0000000000000000f, 1.0000000000000000f, 1.0000000000000000f, 1.0000000000000000f, 1.0000000000000000f, 1.0000000000000000f, 1.0000000000000000f, 1.0000000000000000f, 1.0000000000000000f, 1.0000000000000000f
};
/*!
	Gaussian Error Function
*/
static float fasterf(const float x)
{
	if(x>0) return erftable[(int)(min(6.f,x)*100)];
	return -erftable[(int)(min(6.f,-x)*100)];
}

enum distEnum {DIST_EUCLIDEAN, DIST_MANHATTAN, DIST_INFINITE} ;

inline float Distance(float *a, float *b, u32 dim, distEnum metric)
{
	float dist = 0;
	switch(metric)
	{
	case DIST_EUCLIDEAN:
		FOR(i, dim) dist += powf(a[i]-b[i],2);
		dist = sqrtf(dist);
		break;
	case DIST_MANHATTAN:
		FOR(i, dim) dist += abs(a[i]-b[i]);
		break;
	case DIST_INFINITE:
		FOR(i, dim) dist = max(dist, (float)abs(a[i]-b[i]));
		break;
	}
	return dist;
}

/**
  * Performs soft-kmeans clustering. The number of clusters is inferred from the dimension of means
  * it is advisable to normalize the data in order to avoid numerical problems due to the negative exp function
  *	\param points the input points
  * \param means, the starting cluster positions
  * \param dim, the dimension of the point data
  * \param beta, the stiffness of the soft-kmeans boundary
  * \return returns the weights for each points for each cluster
  *

*/
inline std::vector< std::vector<float> > SoftKMeans(const std::vector<float *> points, std::vector<float *> *means, unsigned int dim, float beta)
{
	unsigned int clusters = means->size();

	std::vector< std::vector<float> > weights;
	for (unsigned int i=0; i < points.size(); i++)
	{
		weights.push_back(std::vector<float>());
		for (unsigned int j=0; j < clusters; j++) weights[i].push_back(0);
	}

	std::vector<float> distances;
	for (unsigned int i=0; i < clusters; i++) distances.push_back(0);


	// Expectation Step
	for (unsigned int i=0; i < points.size(); i++)
	{
		float distanceSum = 0;
		for (unsigned int j=0; j < clusters; j++)
		{
			distances[j] = expf(-beta*Distance(points[i], (*means)[j], dim, DIST_EUCLIDEAN));
			distanceSum += distances[j];
		}

		for (unsigned int j=0; j < clusters; j++)
		{
			weights[i][j] = distances[j] / distanceSum;
		}
	}

	// Maximization Step
	std::vector<float> perCluster;

	for (unsigned int i=0; i < clusters; i++)
	{
		for (unsigned int j=0; j < dim; j++) (*means)[i][j] = 0;
		perCluster.push_back(0);
	}

	for (unsigned int i=0; i < points.size(); i++)
	{
		for (unsigned int j=0; j < clusters; j++)
		{
			for (unsigned int k=0; k < dim; k++)
			{
				(*means)[j][k] += points[i][k] * weights[i][j];
			}
			perCluster[j] += weights[i][j];
		}
	}

	for (unsigned int i=0; i < clusters; i++)
	{
		if(perCluster[i] != 0)
		{
			for (unsigned int j=0; j < dim; j++)
			{
				(*means)[i][j] /= perCluster[i];
			}
		}
	}

	return weights;
}

#endif // _BASICMATH_H_
